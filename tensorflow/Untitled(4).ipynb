{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled",
      "provenance": [],
      "collapsed_sections": [
        "LB6QVnQNYpNE",
        "1cExNI0AXNZG",
        "SExViapYmFQe"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LB6QVnQNYpNE"
      },
      "source": [
        "### Introduction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RMvRvymIL-t"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqQWsWOKIYiQ",
        "outputId": "bfc819e6-b0b9-4e97-e391-66b228635fba"
      },
      "source": [
        "# tensors\n",
        "print(tf.ones((1,)).numpy())\n",
        "print(tf.ones((3,)).numpy())\n",
        "print(tf.ones((5,)).numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.]\n",
            "[1. 1. 1.]\n",
            "[1. 1. 1. 1. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41noniR_Ihtf",
        "outputId": "de84184f-4d40-45ca-b405-3026610283d1"
      },
      "source": [
        "# constants (cannot be changed or trained)\n",
        "print(tf.constant(3, shape = [3,4]))\n",
        "print(tf.constant([1,2,3,4,5,6,6,7], shape = [4,2]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[3 3 3 3]\n",
            " [3 3 3 3]\n",
            " [3 3 3 3]], shape=(3, 4), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[1 2]\n",
            " [3 4]\n",
            " [5 6]\n",
            " [6 7]], shape=(4, 2), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGNmXtNxQVkv",
        "outputId": "0bd2d15d-4196-453c-8e7d-f660b9552069"
      },
      "source": [
        "# Import constant from TensorFlow\n",
        "from tensorflow import constant\n",
        "import numpy as np\n",
        "\n",
        "# Convert the credit_numpy array into a tensorflow constant\n",
        "credit_constant = constant(np.full((7,6), 6))\n",
        "\n",
        "# Print constant datatype\n",
        "print('The datatype is:', credit_constant.dtype)\n",
        "\n",
        "# Print constant shape\n",
        "print('The shape is:', credit_constant.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The datatype is: <dtype: 'int64'>\n",
            "The shape is: (7, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0cssYNdQs1C",
        "outputId": "9af0238f-1609-4e2f-c76b-50cf153e3ae2"
      },
      "source": [
        "# Define the 1-dimensional variable A1\n",
        "import tensorflow as tf\n",
        "A1 = tf.Variable([1, 2, 3, 4])\n",
        "\n",
        "# Print the variable A1\n",
        "print(A1)\n",
        "\n",
        "# Convert A1 to a numpy array and assign it to B1\n",
        "B1 = A1.numpy()\n",
        "\n",
        "# Print B1\n",
        "print(B1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tf.Variable 'Variable:0' shape=(4,) dtype=int32, numpy=array([1, 2, 3, 4], dtype=int32)>\n",
            "[1 2 3 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_YLhzUgJUgk",
        "outputId": "7e1da38d-ba7d-453a-f135-91d2d70e685b"
      },
      "source": [
        "# basic operations\n",
        "# Define the 1-dimensional variable A1\n",
        "import tensorflow as tf\n",
        "A1 = tf.Variable([1, 2, 3, 4])\n",
        "\n",
        "# Print the variable A1\n",
        "print(A1)\n",
        "\n",
        "# Convert A1 to a numpy array and assign it to B1\n",
        "B1 = A1.numpy()\n",
        "\n",
        "# Print B1\n",
        "print(B1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tf.Variable 'Variable:0' shape=(4,) dtype=int32, numpy=array([1, 2, 3, 4], dtype=int32)>\n",
            "[1 2 3 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LSVyDItTL_j",
        "outputId": "ab333152-c0c6-4f0f-9b24-52de2e2ada73"
      },
      "source": [
        "# Define features, params, and bill as constants\n",
        "from tensorflow import matmul\n",
        "features = constant([[2, 24], [2, 26], [2, 57], [1, 37]])\n",
        "params = constant([[1000], [150]])\n",
        "bill = constant([[3913], [2682], [8617], [64400]])\n",
        "\n",
        "# Compute billpred using features and params\n",
        "billpred = matmul(features, params)\n",
        "\n",
        "# Compute and print the error\n",
        "error = bill - billpred\n",
        "print(error.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-1687]\n",
            " [-3218]\n",
            " [-1933]\n",
            " [57850]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwJfYBbXTgzX"
      },
      "source": [
        "# reshaping images (gray and color tensors are predefined)\n",
        "\n",
        "# Reshape the grayscale image tensor into a vector\n",
        "gray_vector = reshape(gray_tensor, (784, 1))\n",
        "\n",
        "# Reshape the color image tensor into a vector\n",
        "color_vector = reshape(color_tensor, (2352, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3frXXWc4WwVI",
        "outputId": "6bf89bc7-c54a-4821-b775-c441e7321980"
      },
      "source": [
        "## gradient calculation\n",
        "from tensorflow import GradientTape\n",
        "def compute_gradient(x0):\n",
        "  \t# Define x as a variable with an initial value of x0\n",
        "\tx = tf.Variable(x0)\n",
        "\twith GradientTape() as tape:\n",
        "\t\ttape.watch(x)\n",
        "        # Define y using the multiply operation\n",
        "\t\ty = tf.multiply(x,x)\n",
        "    # Return the gradient of y with respect to x\n",
        "\treturn tape.gradient(y, x).numpy()\n",
        "\n",
        "# Compute and print gradients at x = -1, 1, and 0\n",
        "print(compute_gradient(-1.0))\n",
        "print(compute_gradient(1.0))\n",
        "print(compute_gradient(0.0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-2.0\n",
            "2.0\n",
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cExNI0AXNZG"
      },
      "source": [
        "### Linear Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1a-4hEyNYtw9"
      },
      "source": [
        "# loss functions\n",
        "\n",
        "# Import the keras module from tensorflow\n",
        "from tensorflow import keras\n",
        "# Compute the mean squared error (mse)\n",
        "loss = keras.losses.mse(price, predictions)\n",
        "\n",
        "# Print the mean squared error (mse)\n",
        "print(loss.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PavZ71hRb1nW"
      },
      "source": [
        "# Initialize a variable named scalar\n",
        "import tensorflow as tf\n",
        "scalar = tf.Variable(1.0, tf.float32)\n",
        "\n",
        "# Define the model\n",
        "def model(scalar, features = features):\n",
        "  \treturn scalar * features\n",
        "\n",
        "# Define a loss function\n",
        "def loss_function(scalar, features = features, targets = targets):\n",
        "\t# Compute the predicted values\n",
        "\tpredictions = model(scalar, features)\n",
        "    \n",
        "\t# Return the mean absolute error loss\n",
        "\treturn keras.losses.mae(targets, predictions)\n",
        "\n",
        "# Evaluate the loss function and print the loss\n",
        "print(loss_function(scalar).numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Pyx36hDcjTr"
      },
      "source": [
        "# linear regression\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "intercept = tf.Variable(0.1, tf.float32)\n",
        "slope = tf.Variable(0.1, tf.float32)\n",
        "\n",
        "# Define a linear regression model\n",
        "def linear_regression(intercept, slope, features = size_log):\n",
        "\treturn intercept + slope*features\n",
        "\n",
        "# Set loss_function() to take the variables as arguments\n",
        "def loss_function(intercept, slope, features = size_log, targets = price_log):\n",
        "\t# Set the predicted values\n",
        "\tpredictions = linear_regression(intercept, slope, features)\n",
        "    \n",
        "    # Return the mean squared error loss\n",
        "\treturn keras.losses.mse(targets, predictions)\n",
        "\n",
        "# Compute the loss for different slope and intercept values\n",
        "print(loss_function(0.1, 0.1).numpy())\n",
        "print(loss_function(0.1, 0.5).numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdigUUMxgpSQ"
      },
      "source": [
        "# Initialize an adam optimizer -- minimisation\n",
        "opt = keras.optimizers.Adam(0.5)\n",
        "\n",
        "for j in range(100):\n",
        "\t# Apply minimize, pass the loss function, and supply the variables\n",
        "\topt.minimize(lambda: loss_function(intercept, slope), var_list=[intercept, slope])\n",
        "\n",
        "\t# Print every 10th value of the loss\n",
        "\tif j % 10 == 0:\n",
        "\t\tprint(loss_function(intercept, slope).numpy())\n",
        "\n",
        "# Plot data and regression line\n",
        "plot_results(intercept, slope)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBrjTEOHhp4H"
      },
      "source": [
        "## tensor vector: intercept+slope+slope\n",
        "\n",
        "# Define the linear regression model\n",
        "def linear_regression(params, feature1 = size_log, feature2 = bedrooms):\n",
        "\treturn params[0] + feature1*params[1] + feature2*params[2]\n",
        "\n",
        "# Define the loss function\n",
        "def loss_function(params, targets = price_log, feature1 = size_log, feature2 = bedrooms):\n",
        "\t# Set the predicted values\n",
        "\tpredictions = linear_regression(params, feature1, feature2)\n",
        "  \n",
        "\t# Use the mean absolute error loss\n",
        "\treturn keras.losses.mae(targets, predictions)\n",
        "\n",
        "# Define the optimize operation\n",
        "opt = keras.optimizers.Adam()\n",
        "\n",
        "# Perform minimization and print trainable variables\n",
        "for j in range(10):\n",
        "\topt.minimize(lambda: loss_function(params), var_list=[params])\n",
        "\tprint_results(params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34uRfOHXiubP"
      },
      "source": [
        "# Initialize adam optimizer\n",
        "opt = keras.optimizers.Adam()\n",
        "\n",
        "# Load data in batches\n",
        "for batch in pd.read_csv('kc_house_data.csv', chunksize=100):\n",
        "\tsize_batch = np.array(batch['sqft_lot'], np.float32)\n",
        "\n",
        "\t# Extract the price values for the current batch\n",
        "\tprice_batch = np.array(batch['price'], np.float32)\n",
        "\n",
        "\t# Complete the loss, fill in the variable list, and minimize\n",
        "\topt.minimize(lambda: loss_function(intercept, slope, price_batch, size_batch), var_list=[intercept, slope])\n",
        "\n",
        "# Print trained parameters\n",
        "print(intercept.numpy(), slope.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SExViapYmFQe"
      },
      "source": [
        "### Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoyzTcpJmL2T"
      },
      "source": [
        "# Initialize bias1\n",
        "bias1 = Variable(1.0)\n",
        "\n",
        "# Initialize weights1 as 3x2 variable of ones\n",
        "weights1 = Variable(ones((3, 2)))\n",
        "\n",
        "# Perform matrix multiplication of borrower_features and weights1\n",
        "product1 = matmul(borrower_features, weights1)\n",
        "\n",
        "# Apply sigmoid activation function to product1 + bias1\n",
        "dense1 = keras.activations.sigmoid(product1 + bias1)\n",
        "\n",
        "# Print shape of dense1\n",
        "print(\"\\n dense1's output shape: {}\".format(dense1.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lU_nsS_Ko9PR"
      },
      "source": [
        "# From previous step '''predefined variables'''\n",
        "bias1 = tf.Variable(1.0)\n",
        "weights1 = tf.Variable(tf.ones((3, 2)))\n",
        "product1 = matmul(borrower_features, weights1)\n",
        "dense1 = keras.activations.sigmoid(product1 + bias1)\n",
        "\n",
        "# Initialize bias2 and weights2\n",
        "bias2 = Variable(1.0)\n",
        "weights2 = Variable(tf.ones((2, 1)))\n",
        "\n",
        "# Perform matrix multiplication of dense1 and weights2\n",
        "product2 = matmul(dense1, weights2)\n",
        "\n",
        "# Apply activation to product2 + bias2 and print the prediction\n",
        "prediction = keras.activations.sigmoid(product2 + bias2)\n",
        "print('\\n prediction: {}'.format(prediction.numpy()[0,0]))\n",
        "print('\\n actual: 1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FKCORrlpTDx"
      },
      "source": [
        "# Compute the product of borrower_features and weights1\n",
        "products1 = matmul(borrower_features, weights1)\n",
        "\n",
        "# Apply a sigmoid activation function to products1 + bias1\n",
        "dense1 = keras.activations.sigmoid(products1 + bias1)\n",
        "\n",
        "# Print the shapes of borrower_features, weights1, bias1, and dense1\n",
        "print('\\n shape of borrower_features: ', borrower_features.shape)\n",
        "print('\\n shape of weights1: ', weights1.shape)\n",
        "print('\\n shape of bias1: ', bias1.shape)\n",
        "print('\\n shape of dense1: ', dense1.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeFx2of-poPY"
      },
      "source": [
        "# Define the first dense layer\n",
        "dense1 = keras.layers.Dense(7, activation='sigmoid')(borrower_features)\n",
        "\n",
        "# Define a dense layer with 3 output nodes\n",
        "dense2 = keras.layers.Dense(3, activation = 'sigmoid')\n",
        "\n",
        "# Define a dense layer with 1 output node\n",
        "predictions = keras.layers.Dense(1, activation = 'sigmoid')\n",
        "\n",
        "# Print the shapes of dense1, dense2, and predictions\n",
        "print('\\n shape of dense1: ', dense1.shape)\n",
        "print('\\n shape of dense2: ', dense2.shape)\n",
        "print('\\n shape of predictions: ', predictions.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDNS0wwTqFan"
      },
      "source": [
        "# Define the first dense layer '''predefined features'''\n",
        "dense1 = tf.keras.layers.Dense(7, activation='sigmoid')(borrower_features)\n",
        "\n",
        "# Define a dense layer with 3 output nodes\n",
        "dense2 = tf.keras.layers.Dense(3, activation = 'sigmoid')\n",
        "\n",
        "# Define a dense layer with 1 output node\n",
        "predictions = tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
        "\n",
        "# Print the shapes of dense1, dense2, and predictions\n",
        "print('\\n shape of dense1: ', dense1.shape)\n",
        "print('\\n shape of dense2: ', dense2.shape)\n",
        "print('\\n shape of predictions: ', predictions.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5-OaMc7rYcd"
      },
      "source": [
        "## activation functions\n",
        "\n",
        "# Construct input layer from features\n",
        "inputs = constant(bill_amounts, float32)\n",
        "\n",
        "# Define first dense layer\n",
        "dense1 = keras.layers.Dense(3, activation='relu')(inputs)\n",
        "\n",
        "# Define second dense layer\n",
        "dense2 = keras.layers.Dense(2, activation = 'relu')(dense1)\n",
        "\n",
        "# Define output layer\n",
        "outputs = keras.layers.Dense(1, activation = 'sigmoid')(dense2)\n",
        "\n",
        "# Print error for first five examples\n",
        "error = default[:5] - outputs.numpy()[:5]\n",
        "print(error)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ac4zKzttlrE"
      },
      "source": [
        "# Construct input layer from borrower features\n",
        "inputs = constant(borrower_features, float32)\n",
        "\n",
        "# Define first dense layer\n",
        "dense1 = keras.layers.Dense(10, activation='sigmoid')(inputs)\n",
        "\n",
        "# Define second dense layer\n",
        "dense2 = keras.layers.Dense(8, activation = 'relu')(dense1)\n",
        "\n",
        "# Define output layer\n",
        "outputs = keras.layers.Dense(6, activation = 'softmax')(dense2)\n",
        "\n",
        "# Print first five predictions\n",
        "print(outputs.numpy()[:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evrfnHQxuPoI"
      },
      "source": [
        "# Initialize x_1 and x_2\n",
        "x_1 = tf.Variable(6.0,float32)\n",
        "x_2 = tf.Variable(0.3,float32)\n",
        "\n",
        "# Define the optimization operation\n",
        "opt = tf.keras.optimizers.SGD(learning_rate=.01)\n",
        "\n",
        "for j in range(100):\n",
        "\t# Perform minimization using the loss function and x_1\n",
        "\topt.minimize(lambda: loss_function(x_1), var_list=[x_1])\n",
        "\t# Perform minimization using the loss function and x_2\n",
        "\topt.minimize(lambda: loss_function(x_2), var_list=[x_2])\n",
        "\n",
        "# Print x_1 and x_2 as numpy arrays\n",
        "print(x_1.numpy(), x_2.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAFWJ3XPwqmH"
      },
      "source": [
        "# Initialize x_1 and x_2\n",
        "x_1 = Variable(0.05,float32)\n",
        "x_2 = Variable(0.05,float32)\n",
        "\n",
        "# Define the optimization operation for opt_1 and opt_2\n",
        "opt_1 = keras.optimizers.RMSprop(learning_rate=.01, momentum=.99)\n",
        "opt_2 = keras.optimizers.RMSprop(learning_rate=.01, momentum=0)\n",
        "\n",
        "for j in range(100):\n",
        "\topt_1.minimize(lambda: loss_function(x_1), var_list=[x_1])\n",
        "    # Define the minimization operation for opt_2\n",
        "\topt_2.minimize(lambda: loss_function(x_2), var_list=[x_2])\n",
        "\n",
        "# Print x_1 and x_2 as numpy arrays\n",
        "print(x_1.numpy(), x_2.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mhi1IwsmxFSW"
      },
      "source": [
        "# initialisation\n",
        "# Define the layer 1 weights\n",
        "w1 = Variable(random.normal([23, 7]))\n",
        "\n",
        "# Initialize the layer 1 bias\n",
        "b1 = Variable(ones([7]))\n",
        "\n",
        "# Define the layer 2 weights\n",
        "w2 = Variable(random.normal([7, 1]))\n",
        "\n",
        "# Define the layer 2 bias\n",
        "b2 = Variable(0.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dc0QRoqZzYKn"
      },
      "source": [
        "# Define the model\n",
        "def model(w1, b1, w2, b2, features = borrower_features):\n",
        "\t# Apply relu activation functions to layer 1\n",
        "\tlayer1 = keras.activations.relu(matmul(features, w1) + b1)\n",
        "    # Apply dropout\n",
        "\tdropout = keras.layers.Dropout(0.25)(layer1)\n",
        "\treturn keras.activations.sigmoid(matmul(dropout, w2) + b2)\n",
        "\n",
        "# Define the loss function\n",
        "def loss_function(w1, b1, w2, b2, features = borrower_features, targets = default):\n",
        "\tpredictions = model(w1, b1, w2, b2)\n",
        "\t# Pass targets and predictions to the cross entropy loss\n",
        "\treturn keras.losses.binary_crossentropy(targets, predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ll6fym6W0HKy"
      },
      "source": [
        "# Train the model\n",
        "for j in range(100):\n",
        "    # Complete the optimizer\n",
        "\topt.minimize(lambda: loss_function(w1, b1, w2, b2), \n",
        "                 var_list=[w1, b1, w2, b2])\n",
        "\n",
        "# Make predictions with model\n",
        "model_predictions = model(w1, b1, w2, b2, test_features)\n",
        "\n",
        "# Construct the confusion matrix\n",
        "confusion_matrix(test_targets, model_predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HVq0Ihp0H3t"
      },
      "source": [
        "### High Level APIs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoEH8rba0MpA"
      },
      "source": [
        "### keras\n",
        "\n",
        "# Define the first dense layer\n",
        "model.add(keras.layers.Dense(16, input_shape = (784,), activation = 'sigmoid'))\n",
        "\n",
        "# Apply dropout to the first layer's output\n",
        "model.add(keras.layers.Dropout(0.25))\n",
        "\n",
        "# Define the output layer\n",
        "model.add(keras.layers.Dense(4, activation = 'softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile('adam', loss='categorical_crossentropy')\n",
        "\n",
        "# Print a model summary\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6wych0T3T5b"
      },
      "source": [
        "# For model 1, pass the input layer to layer 1 and layer 1 to layer 2\n",
        "m1_layer1 = keras.layers.Dense(12, activation='sigmoid')(m1_inputs)\n",
        "m1_layer2 = keras.layers.Dense(4, activation='softmax')(m1_layer1)\n",
        "\n",
        "# For model 2, pass the input layer to layer 1 and layer 1 to layer 2\n",
        "m2_layer1 = keras.layers.Dense(12, activation='relu')(m2_inputs)\n",
        "m2_layer2 = keras.layers.Dense(4, activation='softmax')(m2_layer1)\n",
        "\n",
        "# Merge model outputs and define a functional model\n",
        "merged = keras.layers.add([m1_layer2, m2_layer2])\n",
        "model = keras.Model(inputs=[m1_inputs, m2_inputs], outputs=merged)\n",
        "\n",
        "# Print a model summary\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSw4gICh3pRH"
      },
      "source": [
        "# Define a sequential model\n",
        "import tensorflow as tf\n",
        "model = keras.Sequential()\n",
        "\n",
        "# Define a hidden layer\n",
        "model.add(keras.layers.Dense(16, activation='relu', input_shape=(784,)))\n",
        "\n",
        "# Define the output layer\n",
        "model.add(keras.layers.Dense(4, activation = 'softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile('SGD', loss='categorical_crossentropy')\n",
        "\n",
        "# Complete the fitting operation\n",
        "model.fit(sign_language_features, sign_language_labels, epochs=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "td4IvtWBsdcr"
      },
      "source": [
        "# Define sequential model\n",
        "model = keras.Sequential()\n",
        "\n",
        "# Define the first layer\n",
        "model.add(keras.layers.Dense(32, activation = 'sigmoid', input_shape = (784,)))\n",
        "\n",
        "# Add activation function to classifier\n",
        "model.add(keras.layers.Dense(4, activation='softmax'))\n",
        "\n",
        "# Set the optimizer, loss function, and metrics\n",
        "model.compile(optimizer='RMSprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Add the number of epochs and the validation split\n",
        "model.fit(sign_language_features, sign_language_labels, epochs=10, validation_split=.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xepC59XytLzq"
      },
      "source": [
        "# Define sequential model\n",
        "model = keras.Sequential()\n",
        "\n",
        "# Define the first layer\n",
        "model.add(keras.layers.Dense(1024, activation = 'relu', input_shape = (784,)))\n",
        "\n",
        "# Add activation function to classifier\n",
        "model.add(keras.layers.Dense(4, activation='softmax'))\n",
        "\n",
        "# Finish the model compilation\n",
        "model.compile(optimizer=keras.optimizers.Adam(lr=.001), \n",
        "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Complete the model fit operation\n",
        "model.fit(sign_language_features, sign_language_labels, epochs=50, validation_split=.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSECgxNptmId"
      },
      "source": [
        "# Evaluate the small model using the train data\n",
        "small_train = small_model.evaluate(train_features, train_labels)\n",
        "\n",
        "# Evaluate the small model using the test data\n",
        "small_test = small_model.evaluate(test_features, test_labels)\n",
        "\n",
        "# Evaluate the large model using the train data\n",
        "large_train = large_model.evaluate(train_features, train_labels)\n",
        "\n",
        "# Evaluate the large model using the test data\n",
        "large_test = large_model.evaluate(test_features, test_labels)\n",
        "\n",
        "# Print losses\n",
        "print('\\n Small - Train: {}, Test: {}'.format(small_train, small_test))\n",
        "print('Large - Train: {}, Test: {}'.format(large_train, large_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__44QIAhuDOm"
      },
      "source": [
        "## tf estimators (housing dataset.)\n",
        "\n",
        "# Define feature columns for bedrooms and bathrooms\n",
        "bedrooms = feature_column.numeric_column(\"bedrooms\")\n",
        "bathrooms = feature_column.numeric_column('bathrooms')\n",
        "\n",
        "# Define the list of feature columns\n",
        "feature_list = [bedrooms, bathrooms]\n",
        "\n",
        "def input_fn():\n",
        "\t# Define the labels\n",
        "\tlabels = np.array(housing['price'])\n",
        "\t# Define the features\n",
        "\tfeatures = {'bedrooms':np.array(housing['bedrooms']), \n",
        "                'bathrooms':np.array(housing['bathrooms'])}\n",
        "\treturn features, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SP0hEa7wwabP"
      },
      "source": [
        "# Define the model and set the number of steps\n",
        "model = estimator.DNNRegressor(feature_columns=feature_list, hidden_units=[2,2])\n",
        "model.train(input_fn, steps=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRk572hXwaVR"
      },
      "source": [
        "# Define the model and set the number of steps\n",
        "model = estimator.LinearRegressor(feature_columns=feature_list)\n",
        "model.train(input_fn, steps=2)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}